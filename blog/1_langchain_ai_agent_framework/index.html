<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://caffcen.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://caffcen.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://caffcen.github.io/favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=https://caffcen.github.io/android-chrome-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://caffcen.github.io/apple-touch-icon.png><meta name=description content><title>Code Analysis of LangChain AI Agent Implementation | Lihang Liu's Homepage</title><link rel=canonical href=https://caffcen.github.io/blog/1_langchain_ai_agent_framework/><meta property="og:url" content="https://caffcen.github.io/blog/1_langchain_ai_agent_framework/"><meta property="og:site_name" content="Lihang Liu's Homepage"><meta property="og:title" content="Code Analysis of LangChain AI Agent Implementation"><meta property="og:description" content="Analysis of codes and designs of agent framework in LangChain"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-05-18T15:04:42+08:00"><meta property="article:modified_time" content="2025-11-23T14:59:40-05:00"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Ai_agent"><link rel=stylesheet href=/assets/combined.min.57df9e7d692553f966cff4593ede6b53efb74da234876bacffeac774bd572e53.css media=all></head><body class=auto><div class=content><header><div class=header><h1 class=header-title><a href=https://caffcen.github.io/>Lihang Liu's Homepage</a></h1><div class=header-menu><p class=small><a href=/>/Home</a></p><p class=small><a href=/blog/>/Blog</a></p><p class=small><a href=/archive/>/Archive</a></p></div></div></header><main class=main><div class=breadcrumbs><a href=/>Home</a><span class=breadcrumbs-separator>/</span><a href=/blog/>Blog</a><span class=breadcrumbs-separator>/</span>
<a href=/blog/1_langchain_ai_agent_framework/>Code Analysis of LangChain AI Agent Implementation</a></div><div><article><header class=single-intro-container><h1 class=single-title>Code Analysis of LangChain AI Agent Implementation</h1><p class=single-summary>Analysis of codes and designs of agent framework in LangChain</p><div class=single-subsummary><div><p class=single-date><time datetime=2024-05-18T15:04:42+08:00>May 18, 2024</time>
&nbsp; Â· &nbsp;5 min read</p></div></div></header><div class=single-tags><span><a href=https://caffcen.github.io/tags/llm/>#Llm</a>
</span><span><a href=https://caffcen.github.io/tags/langchain/>#Langchain</a>
</span><span><a href=https://caffcen.github.io/tags/ai_agent/>#Ai_agent</a></span></div><div class=single-content><p>The AI Agent is an innovative way to harness the power of LLM. It provides additional tools and capabilities that empower the LLMs to perform web searches, retrieve data from databases, and invoke general services, among other functions. LangChain offers a well-designed and adaptable implementation of AI agents.</p><p>In this post, I would like to share how the AI agent is implemented and structured in the LangChain project. You can find more information on the LangChain project <a href=https://github.com/langchain-ai/langchain>LangChain</a>.</p><h1 class=heading id=the-agent-module>The Agent Module
<a class=anchor href=#the-agent-module>#</a></h1><h2 class=heading id=the-agent-definition>The Agent Definition
<a class=anchor href=#the-agent-definition>#</a></h2><p><figure><div class=img-container style=--w:934;--h:749><img loading=lazy alt src=/blog/1_langchain_ai_agent_framework/1.png width=934 height=749></div></figure></p><p>An agent is composed of:</p><ol><li>A <code>LLMChain</code> type member represents the large language model to be called.</li><li>An output parser to parse the result of tool execution.</li><li>A list to hold all available tools.</li></ol><p>The key functionality of an agent is the <code>plan()</code> method, it calls the <code>llm_chain</code> to give the next tool to be executed, then the tool is executed and a result is parsed by the <code>output_parser</code>.</p><h2 class=heading id=represent-the-action-of-the-agent>Represent the Action of the Agent
<a class=anchor href=#represent-the-action-of-the-agent>#</a></h2><p>To represent the tool to be executed by the agent, and to encapsulate any necessary data for the agent to execute a tool, <code>AgentAction</code>, <code>AgentStep</code>, and <code>AgentFinish</code> are provided:</p><ul><li><code>AgentAction</code> represents the action to do in the next step which is planned by the llm. To be specific, it is the next tool to be invoked.</li><li><code>AgentStep</code> encapsulates the result of tool execution.</li><li><code>AgentFinish</code> denotes the termination of the entire process. The user&rsquo;s task is considered complete when an <code>AgentFinish</code> object is returned by the agent.</li></ul><p><figure><div class=img-container style=--w:942;--h:446><img loading=lazy alt src=/blog/1_langchain_ai_agent_framework/2.png width=942 height=446></div></figure></p><h2 class=heading id=the-output-parser>The Output Parser
<a class=anchor href=#the-output-parser>#</a></h2><p><figure><div class=img-container style=--w:895;--h:84><img loading=lazy alt src=/blog/1_langchain_ai_agent_framework/3.png width=895 height=84></div></figure></p><p>The output parse should implement the abstract <code>parse()</code> method which is used to get the result of a tool&rsquo;s invocation.</p><h2 class=heading id=the-tool-module>The Tool Module
<a class=anchor href=#the-tool-module>#</a></h2><p>The <code>Tool</code> class represents a tool.</p><p><figure><div class=img-container style=--w:543;--h:771><img loading=lazy alt src=/blog/1_langchain_ai_agent_framework/4.png width=543 height=771></div></figure></p><h2 class=heading id=the-implementation-of-agentexecutor>The Implementation of AgentExecutor
<a class=anchor href=#the-implementation-of-agentexecutor>#</a></h2><p>LangChain uses the idea <code>AgentExecutor</code> to actually chain together all components: <code>Agent</code>, <code>Tools</code>, <code>OutputParser</code>, etc. The tools are added and managed by the <code>AgentExecutor</code>, the iteration of <code>calling the llm for task planning -> the agent picks up the right tool and runs the tool with the parameters given by the llm -> parse the result and feed it to the llm again</code> is all implemented and controlled by the <code>AgentExecutor</code>.</p><p>At the first place, let&rsquo;s see how the <code>AgentExecutor</code> is structured:</p><p><figure><div class=img-container style=--w:868;--h:931><img loading=lazy alt src=/blog/1_langchain_ai_agent_framework/5.png width=868 height=931></div></figure></p><p>As you can see from the uml graph:</p><ul><li>The <code>AgentExecutor</code> holds the <code>Agent</code> object, which is used to make decisions by calling the llm (by invoke the <code>plan()</code> method defined by the <code>Agent</code>).</li><li><code>Tool</code>s are registered to <code>AgentExecutor</code>.</li><li>The <code>max_iterations</code> and <code>max_execution_time</code> are used to control the iteration.</li><li>The actual agent execution is defined and implemented in the member function in <code>AgentExecutor</code>.</li></ul><p>And now let&rsquo;s have a look at how the <code>AgentExecutor</code> works under the hood:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700;text-decoration:underline>def</span> <span style=color:#666;font-weight:700;font-style:italic>_call</span>(  
</span></span><span style=display:flex><span>    <span style=font-weight:700;font-style:italic>self</span>,  
</span></span><span style=display:flex><span>    inputs: Dict[<span style=font-weight:700;font-style:italic>str</span>, <span style=font-weight:700;font-style:italic>str</span>],  
</span></span><span style=display:flex><span>    run_manager: Optional[CallbackManagerForChainRun] = <span style=font-weight:700;text-decoration:underline>None</span>,  
</span></span><span style=display:flex><span>) -&gt; Dict[<span style=font-weight:700;font-style:italic>str</span>, Any]:  
</span></span><span style=display:flex><span>    <span style=color:#666;font-style:italic>&#34;&#34;&#34;Run text through and get agent response.&#34;&#34;&#34;</span>  
</span></span><span style=display:flex><span>    <span style=color:#888;font-style:italic># Construct a mapping of tool name to tool for easy lookup  </span>
</span></span><span style=display:flex><span>    name_to_tool_map = {tool.name: tool <span style=font-weight:700;text-decoration:underline>for</span> tool <span style=font-weight:700>in</span> <span style=font-weight:700;font-style:italic>self</span>.tools}  
</span></span><span style=display:flex><span>    <span style=color:#888;font-style:italic># We construct a mapping from each tool to a color, used for logging.  </span>
</span></span><span style=display:flex><span>    color_mapping = get_color_mapping(  
</span></span><span style=display:flex><span>        [tool.name <span style=font-weight:700;text-decoration:underline>for</span> tool <span style=font-weight:700>in</span> <span style=font-weight:700;font-style:italic>self</span>.tools], excluded_colors=[<span style=color:#666;font-style:italic>&#34;green&#34;</span>, <span style=color:#666;font-style:italic>&#34;red&#34;</span>]  
</span></span><span style=display:flex><span>    )  
</span></span><span style=display:flex><span>    intermediate_steps: List[Tuple[AgentAction, <span style=font-weight:700;font-style:italic>str</span>]] = []  
</span></span><span style=display:flex><span>    <span style=color:#888;font-style:italic># Let&#39;s start tracking the number of iterations and time elapsed  </span>
</span></span><span style=display:flex><span>    iterations = 0  
</span></span><span style=display:flex><span>    time_elapsed = 0.0  
</span></span><span style=display:flex><span>    start_time = time.time()  
</span></span><span style=display:flex><span>    <span style=color:#888;font-style:italic># We now enter the agent loop (until it returns something).  </span>
</span></span><span style=display:flex><span>    <span style=font-weight:700;text-decoration:underline>while</span> <span style=font-weight:700;font-style:italic>self</span>._should_continue(iterations, time_elapsed):  
</span></span><span style=display:flex><span>        next_step_output = <span style=font-weight:700;font-style:italic>self</span>._take_next_step(  
</span></span><span style=display:flex><span>            name_to_tool_map,  
</span></span><span style=display:flex><span>            color_mapping,  
</span></span><span style=display:flex><span>            inputs,  
</span></span><span style=display:flex><span>            intermediate_steps,  
</span></span><span style=display:flex><span>            run_manager=run_manager,  
</span></span><span style=display:flex><span>        )  
</span></span><span style=display:flex><span>        <span style=font-weight:700;text-decoration:underline>if</span> <span style=font-weight:700;font-style:italic>isinstance</span>(next_step_output, AgentFinish):  
</span></span><span style=display:flex><span>            <span style=font-weight:700;text-decoration:underline>return</span> <span style=font-weight:700;font-style:italic>self</span>._return(  
</span></span><span style=display:flex><span>                next_step_output, intermediate_steps, run_manager=run_manager  
</span></span><span style=display:flex><span>            )  
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>        intermediate_steps.extend(next_step_output)  
</span></span><span style=display:flex><span>        <span style=font-weight:700;text-decoration:underline>if</span> <span style=font-weight:700;font-style:italic>len</span>(next_step_output) == 1:  
</span></span><span style=display:flex><span>            next_step_action = next_step_output[0]  
</span></span><span style=display:flex><span>            <span style=color:#888;font-style:italic># See if tool should return directly  </span>
</span></span><span style=display:flex><span>            tool_return = <span style=font-weight:700;font-style:italic>self</span>._get_tool_return(next_step_action)  
</span></span><span style=display:flex><span>            <span style=font-weight:700;text-decoration:underline>if</span> tool_return <span style=font-weight:700>is</span> <span style=font-weight:700>not</span> <span style=font-weight:700;text-decoration:underline>None</span>:  
</span></span><span style=display:flex><span>                <span style=font-weight:700;text-decoration:underline>return</span> <span style=font-weight:700;font-style:italic>self</span>._return(  
</span></span><span style=display:flex><span>                    tool_return, intermediate_steps, run_manager=run_manager  
</span></span><span style=display:flex><span>                )  
</span></span><span style=display:flex><span>        iterations += 1  
</span></span><span style=display:flex><span>        time_elapsed = time.time() - start_time  
</span></span><span style=display:flex><span>    output = <span style=font-weight:700;font-style:italic>self</span>.agent.return_stopped_response(  
</span></span><span style=display:flex><span>        <span style=font-weight:700;font-style:italic>self</span>.early_stopping_method, intermediate_steps, **inputs  
</span></span><span style=display:flex><span>    )  
</span></span><span style=display:flex><span>    <span style=font-weight:700;text-decoration:underline>return</span> <span style=font-weight:700;font-style:italic>self</span>._return(output, intermediate_steps, run_manager=run_manager)
</span></span></code></pre></div><p>Codes explained as follows:</p><ul><li>It initializes an empty list for storing intermediate steps and variables for tracking the number of iterations and time elapsed. The start time is recorded usingÂ <code>time.time()</code>.</li><li>The method enters a loop that continues until theÂ <code>_should_continue</code>Â method returnsÂ <code>False</code>. This method checks whether the agent should continue based on the number of iterations and time elapsed.</li><li>Within the loop, theÂ <code>_take_next_step</code>Â method is called, which performs the next action in the agent&rsquo;s process. It calls the agent to ask the llm to give the tool to be executed and run the tool. The result should be parsed by the <code>output_parse</code> hold by the agent into an <code>AgentStep</code> or an <code>AgentFinish</code>.</li><li>If the output of the next step is an instance ofÂ <code>AgentFinish</code>, theÂ <code>_return</code>Â method is called, which likely finalizes the agent&rsquo;s process and returns the result.</li><li>If the agent hasn&rsquo;t finished, the output of the next step is added to the intermediate steps. If there&rsquo;s only one step in the output, theÂ <code>_get_tool_return</code>Â method is called to check if the tool should return directly. If it should, theÂ <code>_return</code>Â method is called.</li><li>The number of iterations is incremented, and the time elapsed is updated.</li><li>If the loop ends without returning a result, theÂ <code>return_stopped_response</code>Â method of the agent is called, and its output is returned using theÂ <code>_return</code>Â method.</li></ul><h1 class=heading id=overall-structure>Overall Structure
<a class=anchor href=#overall-structure>#</a></h1><p><figure><div class=img-container style=--w:3654;--h:1450><img loading=lazy alt src=/blog/1_langchain_ai_agent_framework/6.png width=3654 height=1450></div></figure></p><h1 class=heading id=summary>Summary
<a class=anchor href=#summary>#</a></h1><p>In this post, we have delved into the implementation details of the LangChain project&rsquo;s AI agent framework. We have discussed key concepts of an agent, how these components are interconnected, and the code details of the execution iteration.</p><h1 class=heading id=reference>Reference
<a class=anchor href=#reference>#</a></h1><ol><li><a href=https://github.com/langchain-ai/langchain>GitHub - langchain-ai/langchain: ğŸ¦œğŸ”— Build context-aware reasoning applications</a></li><li><a href=https://python.langchain.com/v0.1/docs/use_cases/tool_use/agents/>agents | ğŸ¦œï¸ğŸ”— LangChain</a></li><li><a href=https://arxiv.org/abs/2210.03629>[2210.03629] ReAct: Synergizing Reasoning and Acting in Language Models</a></li></ol></div></article><div class=single-comments><script src=https://giscus.app/client.js data-repo data-repo-id data-category data-category-id data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en data-loading=lazy crossorigin=anonymous async></script></div><div class=single-pagination><hr><div class=flexnowrap><div class=single-pagination-prev></div><div class=single-pagination-next><div class=single-pagination-container-next><div class=single-pagination-text><a href=/blog/2_leetcode_trie/>LeetCode Trie Data Structure & Related Problems</a></div><div class=single-pagination-text>â†’</div></div></div></div><hr></div><div class=back-to-top><a href=#top>back to top</a></div></div></main></div><footer><p>Powered by
<a href=https://gohugo.io/>Hugo</a>
and
<a href=https://github.com/tomfran/typo>tomfran/typo</a></p></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></body><script src=/js/theme-switch.js></script><script defer src=/js/copy-code.js></script></html>